{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "2b9bd7ec_a575a9dc",
        "filename": "src/FSAL/Stackable_FSALs/FSAL_MDCACHE/mdcache_lru.c",
        "patchSetId": 1
      },
      "lineNbr": 711,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-12T00:02:22Z",
      "side": 1,
      "message": "I do have a question here - does this elevated reference at the LRU itself cause problems? If we have more threads than lanes trying to reap an entry, it could get locked out. Maybe this should actually be explicit to get a TEMP_REF which would remove the entry from the LRU. But maybe that\u0027s just an argument we need more lanes than CPU threads at least, maybe more than worker threads.",
      "revId": "f4fb613a8f90e0c0790e2ba40603d93aaf86de14",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "953b041b_049dbb5a",
        "filename": "src/FSAL/Stackable_FSALs/FSAL_MDCACHE/mdcache_lru.c",
        "patchSetId": 1
      },
      "lineNbr": 711,
      "author": {
        "id": 1004087
      },
      "writtenOn": "2023-07-13T15:05:12Z",
      "side": 1,
      "message": "This lane is locked.  I think it\u0027s okay.",
      "parentUuid": "2b9bd7ec_a575a9dc",
      "revId": "f4fb613a8f90e0c0790e2ba40603d93aaf86de14",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "ae2dfb7c_768a646b",
        "filename": "src/FSAL/Stackable_FSALs/FSAL_MDCACHE/mdcache_lru.c",
        "patchSetId": 1
      },
      "lineNbr": 711,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-13T18:12:11Z",
      "side": 1,
      "message": "Ah, good point. Hmm, I wonder if we should do a trylock here so we don\u0027t get stuck on an in-use lane? Of course we could be waiting for an unref to put an entry back into this lane, which if we wait a moment for the lock, we might then be able to reap.",
      "parentUuid": "953b041b_049dbb5a",
      "revId": "f4fb613a8f90e0c0790e2ba40603d93aaf86de14",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "aefde4de_3e769907",
        "filename": "src/FSAL/Stackable_FSALs/FSAL_MDCACHE/mdcache_lru.c",
        "patchSetId": 1
      },
      "lineNbr": 711,
      "author": {
        "id": 1004087
      },
      "writtenOn": "2023-07-14T12:55:18Z",
      "side": 1,
      "message": "I don\u0027t think that\u0027s necessary.  Nothing should be holding the qlane lock for extended periods of time.",
      "parentUuid": "ae2dfb7c_768a646b",
      "revId": "f4fb613a8f90e0c0790e2ba40603d93aaf86de14",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c58f2307_2ed0bd00",
        "filename": "src/FSAL/Stackable_FSALs/FSAL_MDCACHE/mdcache_lru.c",
        "patchSetId": 1
      },
      "lineNbr": 711,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-14T14:55:11Z",
      "side": 1,
      "message": "True. Hmm, reaping an entry really should be pretty quick overall (now that we don\u0027t do the close file thing), so with this change, 17 lanes may be plenty. There was some concern we needed enough lanes to cover all the threads to avoid contention. If that truly is no longer an issue, then 17 lanes should be plenty. Though I\u0027d hate to see 1000 threads serialize through the first lane... Another option to fixing contention would be for each thread to start the reap from a different lane instead of everyone starting from lane 0.\n\nMatt thoughts?",
      "parentUuid": "aefde4de_3e769907",
      "revId": "f4fb613a8f90e0c0790e2ba40603d93aaf86de14",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}