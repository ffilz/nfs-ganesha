{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "8e6448ac_4d62ad94",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1020671
      },
      "writtenOn": "2023-07-02T17:17:32Z",
      "side": 1,
      "message": "This is an attempt to fix a bug I accidentally introduced when trying to fix another issue. See the original change here:\nhttps://gerrithub.io/c/ffilz/nfs-ganesha/+/555950\n\nUnfortunately the only way I see to fix it is to not respond to lookups and readdirs during an export update, and pass an internal signal to the FSAL when using lookup for the export update process. \n\nThis is kinda ugly, but I couldn\u0027t really see any other way of fixing it. I\u0027m open to other suggestions though.",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "aad77d0d_e1ea9251",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1004075
      },
      "writtenOn": "2023-07-02T22:31:32Z",
      "side": 1,
      "message": "Is this change fixing the root cause, specifically, that leads to an uninitialized state_hdl?  I\u0027m not expert in the pseudofs, but it sound a bit like this change is doing something else.  I\u0027m surprised that we are introducing a new nfs4_error_delay path as a solution, just going on the reasoning in the comment.",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "f69550b3_ae16bd93",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1020671
      },
      "writtenOn": "2023-07-03T06:41:25Z",
      "side": 1,
      "message": "AFAIU, the root cause is the way MDCache works. \nThe actual handle that is exposed externally is the handle that is kept in MDCache, and the hdl_state is also kept in the MDCache.\nThis means that initializing this info in the handle itself will not help much. \n\nAlso, creating the entries in the PSEUDO FSAL is done using the FSAL MKDIR API, which doesn\u0027t allow to pass junction exports, and so you can\u0027t create the entry in an atomic way. \n\nAll this causes the issue where we create the handle, and then we update the info in the handle, so this is not atomic, and prone to races. This might call for a deeper change in how this works, but it requires a bit more familiarity with the code base than I have. As I said, I\u0027m open for suggestions here. \n\nPersonally, I don\u0027t think it is really a problem not returning a response during a configuration change, it makes sense to not export information while in a transient state, and it is similar to a lock. \nWhat I don\u0027t love about this patch is the need to signal to the FSAL through the op_ctx-\u003efsal_private in lookup during the update.",
      "parentUuid": "aad77d0d_e1ea9251",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "208f24cb_ff43a256",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-03T15:01:46Z",
      "side": 1,
      "message": "It looks like fsal_pseudo already makes use of fsal_private for readdir calling lookup.\n\nI suggest adding a separate field to request_op_context.",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "0acbb596_717bcf04",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 1
      },
      "lineNbr": 0,
      "author": {
        "id": 1020671
      },
      "writtenOn": "2023-07-05T11:19:51Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "8e6448ac_4d62ad94",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "3879f02a_17e6a7f4",
        "filename": "src/FSAL/FSAL_PSEUDO/handle.c",
        "patchSetId": 1
      },
      "lineNbr": 358,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-03T15:01:46Z",
      "side": 1,
      "message": "Note that you are overloading fsal_private, see line 367 below...\n\nWhy not just add a boolean into request_op_context? Or add a field for flags and define a flag for this (then anything in the future that needs a flag can just add a new flag).",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9d93a20d_b3f88a01",
        "filename": "src/FSAL/FSAL_PSEUDO/handle.c",
        "patchSetId": 1
      },
      "lineNbr": 358,
      "author": {
        "id": 1020671
      },
      "writtenOn": "2023-07-04T08:18:57Z",
      "side": 1,
      "message": "Done",
      "parentUuid": "3879f02a_17e6a7f4",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9e7fba0f_1f8407e5",
        "filename": "src/FSAL/FSAL_PSEUDO/handle.c",
        "patchSetId": 1
      },
      "lineNbr": 366,
      "author": {
        "id": 1003571
      },
      "writtenOn": "2023-07-03T15:01:46Z",
      "side": 1,
      "message": "Below is a conflicting use of fsal_private.",
      "revId": "e1972ea744e945d25180c10e03e886bd00c380ee",
      "serverId": "d5d70762-12d0-45a1-890d-524b12d3f735"
    }
  ]
}